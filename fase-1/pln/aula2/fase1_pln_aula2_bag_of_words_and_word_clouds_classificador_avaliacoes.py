# -*- coding: utf-8 -*-
"""fase1_pln_aula2_bag_of_words_and_word_clouds_classificador_avaliacoes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13e3Uqf297Wb3e1rXN_1OT8aOxldpqkK1

# Criando um modelo classificar e avaliação

Utilizando uma base de dados do busca de pé iremos criar um modelo para classificar e avaliar os comentários.

## Importando a base de dados

https://www.kaggle.com/code/abnerfreitas/nlp-buscape-data-ptbr-sentiment-analysis/input
"""

import pandas as pd

avaliacoes = pd.read_csv('b2w.csv')

avaliacoes.head()

"""## Limpeza da base de dados

Retirando as colunas que não são necessárias.
"""

avaliacoes = avaliacoes.drop(['original_index', 'review_text_processed', 'review_text_tokenized', 'rating', 'kfold_polarity', 'kfold_rating'], axis=1)

avaliacoes.head()

"""Remevendo as colunas com valores nulos."""

avaliacoes.info()

avaliacoes.isnull().all().count().sum()

avaliacoes.dropna(inplace=True, axis=0)
avaliacoes

# avaliacoes.polarity.value_counts()
avaliacoes['polarity'].value_counts()

"""## Separando os dados de treino e teste"""

from sklearn.model_selection import train_test_split

treino, teste, classe_treino, classe_teste = train_test_split(avaliacoes.review_text, avaliacoes.polarity,
                                                              stratify=avaliacoes.polarity,
                                                              random_state=71)

classe_teste

"""## Criando um modelo"""

# Linear Model - Logistic Regression
# from sklearn.linear_model import LogisticRegression

# regressao_ligistica = LogisticRegression()
# regressao_ligistica.fit(treino, classe_treino)
# acuracia = regressao_ligistica.score(teste, classe_teste)
# print(acuracia)

# bag of words
from sklearn.feature_extraction.text import CountVectorizer

texto = ['Este produto é muito bom', 'Este produto é muito ruim']
vetorizar = CountVectorizer()
bag_of_words = vetorizar.fit_transform(texto)

bag_of_words

matriz_esparsa = pd.DataFrame.sparse.from_spmatrix(bag_of_words, columns=vetorizar.get_feature_names_out())

matriz_esparsa

"""Vamos aplicar o bag of words na nossa base"""

vetorizar = CountVectorizer()
bag_of_words = vetorizar.fit_transform(avaliacoes.review_text)
print(bag_of_words.shape)

"""116058 -> quatidade de linhas<br/>
50508 -> quantidade de palavras únicas
"""

vetorizar = CountVectorizer(max_features=100) # max_features -> limitando para as 100 palavras que mais se repetem
bag_of_words = vetorizar.fit_transform(avaliacoes.review_text)
print(bag_of_words.shape)

from sklearn.linear_model import LogisticRegression

treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words,
                                                              avaliacoes.polarity,
                                                              stratify=avaliacoes.polarity,
                                                              random_state=71)

regressao_logistica = LogisticRegression()
regressao_logistica.fit(treino, classe_treino)
acuracia = regressao_logistica.score(teste, classe_teste)
print(acuracia)

from sklearn.linear_model import LogisticRegression

def treinar_modelo(dados, coluna_texto, coluna_sentimento):
  vetorizar = CountVectorizer(max_features=100) # max_features -> limitando para as 100 palavras que mais se repetem
  bag_of_words = vetorizar.fit_transform(dados[coluna_texto])

  treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words,
                                                              dados[coluna_sentimento],
                                                              stratify=dados[coluna_sentimento],
                                                              random_state=71)

  regressao_logistica = LogisticRegression()
  regressao_logistica.fit(treino, classe_treino)
  return regressao_logistica.score(teste, classe_teste)

print(treinar_modelo(avaliacoes, 'review_text', 'polarity'))

"""# World Cloud

Visualizando as principais reviews com uma word cloud.

https://github.com/amueller/word_cloud
"""

from wordcloud import WordCloud

todas_avaliacoes = [texto for texto in avaliacoes.review_text]
todas_palavras = ' '.join(todas_avaliacoes)

len(todas_avaliacoes)

len(todas_palavras)

nuvem_palavras = WordCloud().generate(todas_palavras)

nuvem_palavras

import matplotlib.pyplot as plt

plt.figure()
plt.imshow(nuvem_palavras)

nuvem_palavras = WordCloud(width=800, height=500, max_font_size=110).generate(todas_palavras)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 7))
plt.imshow(nuvem_palavras, interpolation='bilinear')
plt.axis('off')
plt.show()

"""## Avaliações negativas e positivas"""

def word_cloud_neg(dados, coluna_texto):
  texto_negativo = dados.query('polarity == 0')
  todas_avaliacoes = [texto for texto in texto_negativo[coluna_texto]]
  todas_palavras = ' '.join(todas_avaliacoes)
  # collocations -> retira as palvras em conjunto (ex: muito bom) e deixa somente palavras únicas
  nuvem_palavras = WordCloud(width=800, height=500, max_font_size=110, collocations=False).generate(todas_palavras)

  plt.figure(figsize=(10, 7))
  plt.imshow(nuvem_palavras, interpolation='bilinear')
  plt.axis('off')
  plt.show()

def word_cloud_pos(dados, coluna_texto):
  texto_positivo = dados.query('polarity == 1')
  todas_avaliacoes = [texto for texto in texto_positivo[coluna_texto]]
  todas_palavras = ' '.join(todas_avaliacoes)
  # collocations -> retira as palvras em conjunto (ex: muito bom) e deixa somente palavras únicas
  nuvem_palavras = WordCloud(width=800, height=500, max_font_size=110, collocations=False).generate(todas_palavras)

  plt.figure(figsize=(10, 7))
  plt.imshow(nuvem_palavras, interpolation='bilinear')
  plt.axis('off')
  plt.show()

word_cloud_neg(avaliacoes, 'review_text')

word_cloud_pos(avaliacoes, 'review_text')

"""OBS: nos gráficos existem as **stop words**, que são palavras que não fazem muito sentido na avalição do gráfico. Ex: na, dos, ao, já, ..."""