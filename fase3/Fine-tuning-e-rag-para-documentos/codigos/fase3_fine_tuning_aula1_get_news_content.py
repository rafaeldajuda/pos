# -*- coding: utf-8 -*-
"""fase3_fine_tuning_aula1_get-news-content.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10uAIUm__jxzKkGoiRHVYd2fmYA4uvwhV
"""

#Conexão com o Google Drive

from google.colab import drive
drive.mount('/content/drive')

import requests
from bs4 import BeautifulSoup
import json

def get_news_content(links_file):
    # Carrega o arquivo com os links e retorna uma lista
    with open(links_file, 'r') as file:
        links = set(file.readlines())
    news_contents = []

    for link in links:
        link = link.strip()  # Limpa a URL, se necessário
        print(link)
        response = requests.get(link)
        print("http status:", response.status_code)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')

            # Localiza o elemento que contém o conteúdo do artigo
            article_content = soup.find('div', class_='article__content')
            if article_content:
                paragraphs = article_content.find_all('p', class_='paragraph inline-placeholder vossi-paragraph-primary-core-light')
                # Concatena o texto de todos os parágrafos encontrados
                content = ' '.join(p.get_text(strip=True) for p in paragraphs)
                news_contents.append(content)
                print(content)
            else:
                news_contents.append("Conteúdo não encontrado.")
        else:
            news_contents.append(f"Falha ao extrair o conteúdo da notícia: {response.status_code}")

    # Salva o conteúdo em um arquivo JSON
    with open('news_contents.json', 'w') as json_file:
        json.dump({"news_content": news_contents}, json_file)

# Chamada da função para extrair os conteúdos
get_news_content('/content/drive/MyDrive/CNN_Links.txt')